{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of data_preprocessing_tools.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mislam3/Machine-Learning-Data-Science-w-Python-R-w.through/blob/master/Copy_of_data_preprocessing_tools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37puETfgRzzg",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing Tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoRP98MpR-qj",
        "colab_type": "text"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFjQwjM0HqWv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np                # NumPy allows us to work with arrays\n",
        "import matplotlib.pyplot as plt   # MatPlotLib Allows us to plot charts and graphs\n",
        "import pandas as pd               # Pandas to import datasets and create matrix of features and dependent variable vectors\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RopL7tUZSQkT",
        "colab_type": "text"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amj5vlbvJKA5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import csv to Python\n",
        "dataset = pd.read_csv('Data.csv') #creates dataframe in dataset var using pandas library function\n",
        "\n",
        "# create two new entities: matrix of features and dependent variable vector\n",
        "# features (independent variable): columns with which to predict the dependent variable ;;; dependent variable: last column in eg. DS Purchased? y/n\n",
        "# typical format to use in DSci and ML: features (ind. var) in first columns and dependent var in the last column\n",
        "\n",
        "# now create separate entities: x-> set of features (col: A-C), y -> dependent var (col D)\n",
        "X = dataset.iloc[:, :-1].values  # iloc[] function locates indexes - columns to extract from the dataset; [rows, columns] parameter format;  : for all the rows i.e. range; in Python index starts at 0 and range includes lower bound but excludes upper bound, so -1 indicates last column\n",
        "y = dataset.iloc[:, -1].values\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5EmOvk8Oo2u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "a8d0084d-76b8-4018-f69c-8b68df8df429"
      },
      "source": [
        "print(X)\n",
        "print(y)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 nan]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' nan 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n",
            "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhfKXNxlSabC",
        "colab_type": "text"
      },
      "source": [
        "## Taking care of missing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlUObcFGQWV2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "0ef5ddfe-e3ae-40c9-8f39-030af5aee3a7"
      },
      "source": [
        "# Don't want missing data- can get error while training ML models\n",
        "# one way is to ignore the observation by deleting it- works if working on large dataset where a tiny fraction won't change the learning quality of the model by much (eg. 1%)\n",
        "# lots of missing data : replace missing data by average/median/most-frequent-value (eg. for categories) of all values of column of which the data is missing (avg. of salaries, here)\n",
        "# SciKit-Learn libraries -Great for Data Pre-Processing\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean') # np -> numpy, nan ->refers to all missing values, imputer -> object\n",
        "\n",
        "# apply imputer object to matrix of features . fit method connects imputer object to matrix of features; transform applies the method to missing salaries\n",
        "imputer.fit(X[:, 1:3]) # parameter expects col with only numerical values- exclude string columns and select all numerical columns; range excludes last col hence 1:3\n",
        "\n",
        "# imputer.transform(X[:, 1:3])\n",
        "# update matrix of features X\n",
        "X[:, 1:3] = imputer.transform(X[:, 1:3])\n",
        "\n",
        "print(X)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 63777.77777777778]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' 38.77777777777778 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CriG6VzVSjcK",
        "colab_type": "text"
      },
      "source": [
        "## Encoding categorical data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhSpdQWeSsFh",
        "colab_type": "text"
      },
      "source": [
        "### Encoding the Independent Variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VN-OcDE29ql-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "42ad076d-7132-4f4b-f60b-542342c1cc4e"
      },
      "source": [
        "# in our dataset, if we categorize countries as numbers, ML model might associate meaning with those numerical values, perhaps as some order, etc. which could be detrimental in this case\n",
        "# avoid model to have such interpretation- might cause misinterpreted correlations between features and the outcome to be predicted\n",
        "# implement On-Hot-Encoding : here, make 3 columns for Germany, Spain, and France Creates binary vectors for each countries. Encodes to 100, 010, 001 where no numerical order exists\n",
        "# Finally, replace dependent variable Purchased -> No/Yes with 0/1 where binary outcome is proper\n",
        "\n",
        "# One Hot coding for countries\n",
        "# scikit learn\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# create object of column transformer class\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder = 'passthrough') # parameters: (kind of transformation to columns(tuple), remainder where transform does not apply) ; 0 since we only need to apply to 1st column or 0 index\n",
        "# passthrough to keep the columns not one-hot-encoded into matrix of features (age and salary)\n",
        "# connect ct to matrix of features X\n",
        "\n",
        "# X = ct.fit_transform(X) # X to one hot encode country column; returns new matrix of features output of 3 columns one hot encoding country col - exactly what we want so update X w/ =\n",
        "# fit doesn't return output as numpy array but it is required to have the matrix of features X as numpy array as it might be expected by future ML models\n",
        "# force fit transform to output numpy array\n",
        "\n",
        "X = np.array(ct.fit_transform(X))\n",
        "\n",
        "print(X)\n",
        "\n",
        "# Encoded unique id: France as 1 0 0, Spain as 0 0 1, Germany as 0 1 0 --- prevented numerical ordering by one-hot-encoding a categorical data"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [0.0 1.0 0.0 30.0 54000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 35.0 58000.0]\n",
            " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXh8oVSITIc6",
        "colab_type": "text"
      },
      "source": [
        "### Encoding the Dependent Variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7g8IA50O-VyQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b064835c-574e-4ea7-cb5e-7590966e78e4"
      },
      "source": [
        "# Now, another class called Label Encoder for Purchased=No/Yes to 0/1\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#create object of the LabelEncoder class- directly input y hence no parameter in parentheses as we are dealing with one vector\n",
        "le = LabelEncoder()\n",
        "\n",
        "y = le.fit_transform(y) # to encode/convert no/yes to 0/1 - expects numpy array\n",
        "\n",
        "print(y)\n",
        "\n",
        "# Label Encoding might be useful for elements such as degrees eg. low, mid, high as 0, 1, 2 respectively where even if high is considered to have more weight, it would be meaningful vs. use one hot encoding for instances such as this where all elements carry equal weight or..."
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 0 0 1 1 0 1 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb_vcgm3qZKW",
        "colab_type": "text"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpGqbS4TqkIR",
        "colab_type": "text"
      },
      "source": [
        "## Feature Scaling"
      ]
    }
  ]
}